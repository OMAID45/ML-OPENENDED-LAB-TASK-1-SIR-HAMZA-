{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "# Welcome to Colab!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIlRGNmh57TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAME : OMAID BIN EJAZ\n",
        "ROLL NO : 22F-BSAI-45\n",
        "STUDENT DATA SET"
      ],
      "metadata": {
        "id": "6FNIUblAALFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# student_performance_predictor.py\n",
        "# ------------------------------------------------------------\n",
        "# Student Performance Predictor\n",
        "#\n",
        "#  1. Load and combine UCI student-mat and student-por datasets (remove 382 duplicates)\n",
        "#  2. Select features: studytime, absences, G1, G2, and target G3\n",
        "#  3. Create pass/fail label (>=10 pass)\n",
        "#  4. Preprocess (train/test split + scaling)\n",
        "#  5. Train Linear Regression for G3 prediction\n",
        "#  6. Train Logistic Regression and Decision Tree for pass/fail\n",
        "#  7. Evaluate and detect/explain overfitting (concise)\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# ---------------------------\n",
        "# 1) first i'm Loading  and merging datasets\n",
        "# ---------------------------\n",
        "# Files use ';' separator\n",
        "mat = pd.read_csv('student-mat.csv', sep=';')\n",
        "por = pd.read_csv('student-por.csv', sep=';')\n",
        "print(f\"Loaded: math={mat.shape}, portuguese={por.shape}\")\n",
        "\n",
        "# i just  Merge both datasets on common student-identifying attributes to remove duplicates right!\n",
        "merge_cols = [\n",
        "    'school','sex','age','address','famsize','Pstatus',\n",
        "    'Medu','Fedu','Mjob','Fjob','reason','guardian'\n",
        "]\n",
        "merged = pd.merge(mat, por, on=merge_cols, suffixes=('_mat', '_por'), how='outer')\n",
        "print(f\"Merged shape (unique students): {merged.shape}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2)in this we Select relevant columns\n",
        "# ---------------------------\n",
        "# Some students may appear only in one course so use available columns safely\n",
        "# We will  prefer math grades where available otherwise Portuguese.\n",
        "merged['studytime'] = merged['studytime_mat'].fillna(merged['studytime_por'])\n",
        "merged['absences']  = merged['absences_mat'].fillna(merged['absences_por'])\n",
        "merged['G1'] = merged['G1_mat'].fillna(merged['G1_por'])\n",
        "merged['G2'] = merged['G2_mat'].fillna(merged['G2_por'])\n",
        "merged['G3'] = merged['G3_mat'].fillna(merged['G3_por'])\n",
        "\n",
        "data = merged[['studytime', 'absences', 'G1', 'G2', 'G3']].dropna()\n",
        "print('Final dataset shape after merge:', data.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# 3) now we Create classification label\n",
        "# ---------------------------\n",
        "data['pass_fail'] = (data['G3'] >= 10).astype(int)\n",
        "\n",
        "# ---------------------------\n",
        "# 4)we basically Prepare features, targets, split, and scale on this\n",
        "# ---------------------------\n",
        "X = data[['studytime', 'absences', 'G1', 'G2']]\n",
        "Y_reg = data['G3']         # regression target\n",
        "Y_clf = data['pass_fail']  # classification target\n",
        "\n",
        "# Train-test split (same indices for regression/classification for fair comparison)\n",
        "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
        "    X, Y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "_, _, y_train_clf, y_test_clf = train_test_split(\n",
        "    X, Y_clf, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# i'm doing Scaling features so all variables will be on same scale\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Linear Regression: predict G3 (final marks)\n",
        "# ---------------------------\n",
        "lin = LinearRegression()\n",
        "lin.fit(X_train_s, y_train_reg)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train_reg = lin.predict(X_train_s)\n",
        "y_pred_test_reg = lin.predict(X_test_s)\n",
        "\n",
        "# Evaluation\n",
        "mae_train = mean_absolute_error(y_train_reg, y_pred_train_reg)\n",
        "mae_test = mean_absolute_error(y_test_reg, y_pred_test_reg)\n",
        "r2_train = r2_score(y_train_reg, y_pred_train_reg)\n",
        "r2_test = r2_score(y_test_reg, y_pred_test_reg)\n",
        "\n",
        "print(\"\\nLinear Regression:\")\n",
        "print(f\" Train MAE={mae_train:.2f}, R2={r2_train:.2f}\")\n",
        "print(f\" Test MAE={mae_test:.2f}, R2={r2_test:.2f}\")\n",
        "\n",
        "# Overfitting heuristic\n",
        "if (r2_train - r2_test) > 0.1:\n",
        "    print(\"  Regression overfitting detected (train R2 >> test R2).\")\n",
        "    print(\"Possible cause: correlated features (G1, G2 ~ G3).\")\n",
        "else:\n",
        "    print(\"  Regression shows no strong overfitting.\")\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Logistic Regression: classify pass/fail\n",
        "# ---------------------------\n",
        "log = LogisticRegression(max_iter=1000)\n",
        "log.fit(X_train_s, y_train_clf)\n",
        "\n",
        "y_pred_train_log = log.predict(X_train_s)\n",
        "y_pred_test_log = log.predict(X_test_s)\n",
        "\n",
        "acc_train_log = accuracy_score(y_train_clf, y_pred_train_log)\n",
        "acc_test_log = accuracy_score(y_test_clf, y_pred_test_log)\n",
        "prec_test_log = precision_score(y_test_clf, y_pred_test_log)\n",
        "rec_test_log = recall_score(y_test_clf, y_pred_test_log)\n",
        "\n",
        "print(\"\\nLogistic Regression:\")\n",
        "print(f\" Train Acc={acc_train_log:.2f} | Test Acc={acc_test_log:.2f}\")\n",
        "print(f\" Test Precision={prec_test_log:.2f}, Recall={rec_test_log:.2f}\")\n",
        "print(\" Confusion Matrix (test):\\n\", confusion_matrix(y_test_clf, y_pred_test_log))\n",
        "\n",
        "if (acc_train_log - acc_test_log) > 0.05:\n",
        "    print(\"  Logistic Regression may overfit (train acc higher). Consider regularization or more data.\")\n",
        "else:\n",
        "    print(\"  Logistic Regression generalizes well.\")\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Decision Tree: classify pass/fail\n",
        "# ---------------------------\n",
        "clf_tree = DecisionTreeClassifier(random_state=42, max_depth=4)\n",
        "clf_tree.fit(X_train_s, y_train_clf)\n",
        "\n",
        "y_pred_train_tree = clf_tree.predict(X_train_s)\n",
        "y_pred_test_tree = clf_tree.predict(X_test_s)\n",
        "\n",
        "acc_train_tree = accuracy_score(y_train_clf, y_pred_train_tree)\n",
        "acc_test_tree = accuracy_score(y_test_clf, y_pred_test_tree)\n",
        "prec_test_tree = precision_score(y_test_clf, y_pred_test_tree)\n",
        "rec_test_tree = recall_score(y_test_clf, y_pred_test_tree)\n",
        "\n",
        "print(\"\\nDecision Tree:\")\n",
        "print(f\" Train Acc={acc_train_tree:.2f} | Test Acc={acc_test_tree:.2f}\")\n",
        "print(f\" Test Precision={prec_test_tree:.2f}, Recall={rec_test_tree:.2f}\")\n",
        "print(\" Confusion Matrix (test):\\n\", confusion_matrix(y_test_clf, y_pred_test_tree))\n",
        "\n",
        "if (acc_train_tree - acc_test_tree) > 0.05:\n",
        "    print(\"  Decision Tree likely overfitting (train > test). Try smaller max_depth or use ensembles.\")\n",
        "else:\n",
        "    print(\"  Decision Tree generalizes reasonably well with max_depth=4.\")\n",
        "\n",
        "# ---------------------------\n",
        "# 8)finalizing\n",
        "# ---------------------------\n",
        "print(\"\\nSummary:\")\n",
        "print(f\" - Linear Regression → Test R2={r2_test:.2f}, MAE={mae_test:.2f}\")\n",
        "print(f\" - Logistic Regression → Acc={acc_test_log:.2f}, Prec={prec_test_log:.2f}, Recall={rec_test_log:.2f}\")\n",
        "print(f\" - Decision Tree → Acc={acc_test_tree:.2f}, Prec={prec_test_tree:.2f}, Recall={rec_test_tree:.2f}\")\n",
        "\n",
        "print(\"\\nNotes on overfitting:\")\n",
        "print(\" - Overfitting = model learns noise, not true patterns.\")\n",
        "print(\" - Signs: much better train metrics than test metrics.\")\n",
        "print(\" - Causes: correlated inputs (G1,G2), small data, deep trees.\")\n",
        "print(\" - Fixes: simpler model, regularization, constrain tree depth, use cross-validation, or more data.\")\n",
        "print(\"\\nScript finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zpjjLtG-2dw",
        "outputId": "e992ae91-6ac7-4f26-d508-00ee89dc27a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: math=(395, 33), portuguese=(649, 33)\n",
            "Merged shape (unique students): (682, 54)\n",
            "Final dataset shape after merge: (682, 5)\n",
            "\n",
            "Linear Regression:\n",
            " Train MAE=0.98, R2=0.84\n",
            " Test MAE=1.18, R2=0.82\n",
            "  Regression shows no strong overfitting.\n",
            "\n",
            "Logistic Regression:\n",
            " Train Acc=0.89 | Test Acc=0.93\n",
            " Test Precision=0.92, Recall=0.98\n",
            " Confusion Matrix (test):\n",
            " [[33  8]\n",
            " [ 2 94]]\n",
            "  Logistic Regression generalizes well.\n",
            "\n",
            "Decision Tree:\n",
            " Train Acc=0.91 | Test Acc=0.94\n",
            " Test Precision=0.94, Recall=0.98\n",
            " Confusion Matrix (test):\n",
            " [[35  6]\n",
            " [ 2 94]]\n",
            "  Decision Tree generalizes reasonably well with max_depth=4.\n",
            "\n",
            "Summary:\n",
            " - Linear Regression → Test R2=0.82, MAE=1.18\n",
            " - Logistic Regression → Acc=0.93, Prec=0.92, Recall=0.98\n",
            " - Decision Tree → Acc=0.94, Prec=0.94, Recall=0.98\n",
            "\n",
            "Notes on overfitting:\n",
            " - Overfitting = model learns noise, not true patterns.\n",
            " - Signs: much better train metrics than test metrics.\n",
            " - Causes: correlated inputs (G1,G2), small data, deep trees.\n",
            " - Fixes: simpler model, regularization, constrain tree depth, use cross-validation, or more data.\n",
            "\n",
            "Script finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MY COMPARASION ANALYSIS\n",
        "# Linear Regression accurately predicts final grades (since G1 and G2 are strong predictors of G3).\n",
        "# Logistic Regression classifies pass/fail reliably without overfitting.\n",
        "# Decision Tree performs well but overfits if depth isn’t controlled."
      ],
      "metadata": {
        "id": "rPZ3Zo8JDCET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eaqQqZvXJRwA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}